{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loan Approval Prediction - End-to-End Workflow\n",
        "\n",
        "**üéØ Goal**: We will apply a Supervised Learning workflow on the Loan Approval dataset to predict whether a loan application will be approved or not.\n",
        "\n",
        "**üóíÔ∏è Scenario**\n",
        "\n",
        "The Loan Approval dataset contains information about loan applicants, including their personal details, financial information, and loan characteristics. Our task is to build a model that can predict loan approval status.\n",
        "\n",
        "**‚ö° Task**\n",
        "\n",
        "## 1. Imports and Data Loading\n",
        "\n",
        "First, we import the necessary libraries and load the dataset from the provided URL. We then inspect the dataframe to understand its structure and check for missing values, which determines our preprocessing strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(614, 13)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the dataset from the provided URL\n",
        "loan_data = pd.read_csv('https://raw.githubusercontent.com/prasertcbs/basic-dataset/refs/heads/master/Loan-Approval-Prediction.csv')\n",
        "\n",
        "# Display the shape of the dataset\n",
        "loan_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loan_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Married</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>Education</th>\n",
              "      <th>Self_Employed</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "      <th>Property_Area</th>\n",
              "      <th>Loan_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LP001002</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>5849</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LP001003</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>4583</td>\n",
              "      <td>1508.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Rural</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LP001005</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LP001006</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>2583</td>\n",
              "      <td>2358.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LP001008</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>6000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
              "0  LP001002   Male      No          0      Graduate            No   \n",
              "1  LP001003   Male     Yes          1      Graduate            No   \n",
              "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
              "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
              "4  LP001008   Male      No          0      Graduate            No   \n",
              "\n",
              "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
              "0             5849                0.0         NaN             360.0   \n",
              "1             4583             1508.0       128.0             360.0   \n",
              "2             3000                0.0        66.0             360.0   \n",
              "3             2583             2358.0       120.0             360.0   \n",
              "4             6000                0.0       141.0             360.0   \n",
              "\n",
              "   Credit_History Property_Area Loan_Status  \n",
              "0             1.0         Urban           Y  \n",
              "1             1.0         Rural           N  \n",
              "2             1.0         Urban           Y  \n",
              "3             1.0         Urban           Y  \n",
              "4             1.0         Urban           Y  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the first 5 rows to inspect data types and example values\n",
        "loan_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Loan_Status\n",
              "Y    422\n",
              "N    192\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the distribution of the target variable to see if classes are balanced\n",
        "loan_data['Loan_Status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Loan_ID               0\n",
              "Gender               13\n",
              "Married               3\n",
              "Dependents           15\n",
              "Education             0\n",
              "Self_Employed        32\n",
              "ApplicantIncome       0\n",
              "CoapplicantIncome     0\n",
              "LoanAmount           22\n",
              "Loan_Amount_Term     14\n",
              "Credit_History       50\n",
              "Property_Area         0\n",
              "Loan_Status           0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Identify columns with missing values to decide on imputation strategies\n",
        "loan_data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Selection and Splitting\n",
        "\n",
        "We separate the data into the feature matrix (X) and the target vector (y) as specified in the assignment. We will identify numerical and categorical features to build appropriate preprocessing pipelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature columns:\n",
            "['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Property_Area']\n",
            "\n",
            "Data types:\n",
            "Loan_ID               object\n",
            "Gender                object\n",
            "Married               object\n",
            "Dependents            object\n",
            "Education             object\n",
            "Self_Employed         object\n",
            "ApplicantIncome        int64\n",
            "CoapplicantIncome    float64\n",
            "LoanAmount           float64\n",
            "Loan_Amount_Term     float64\n",
            "Credit_History       float64\n",
            "Property_Area         object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Split features and target as specified in assignment.md\n",
        "X = loan_data.drop('Loan_Status', axis=1)\n",
        "y = loan_data['Loan_Status']\n",
        "\n",
        "# Display feature names and data types\n",
        "print(\"Feature columns:\")\n",
        "print(X.columns.tolist())\n",
        "print(\"\\nData types:\")\n",
        "print(X.dtypes)\n",
        "\n",
        "# Encode target variable from 'Y'/'N' to 1/0 for sklearn compatibility\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "print(f\"\\nTarget variable encoding: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n",
        "print(f\"Target distribution after encoding:\\n{pd.Series(y).value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numerical features: ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n",
            "Categorical features: ['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area']\n"
          ]
        }
      ],
      "source": [
        "# Identify numerical and categorical features\n",
        "# Numerical features are typically int64 or float64\n",
        "# Categorical features are typically object type\n",
        "# Note: Exclude Loan_ID as it's just an identifier and not useful for prediction\n",
        "\n",
        "numerical_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Remove Loan_ID from categorical features if present\n",
        "if 'Loan_ID' in categorical_features:\n",
        "    categorical_features.remove('Loan_ID')\n",
        "\n",
        "print(\"Numerical features:\", numerical_features)\n",
        "print(\"Categorical features:\", categorical_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Building the Pre-Processing Pipeline\n",
        "\n",
        "This is the core of the workflow. We use Pipeline to chain sequential steps (like imputation and scaling) and ColumnTransformer to apply these different pipelines to specific columns (numerical vs. categorical) simultaneously.\n",
        "\n",
        "- **Numerical Data**: We fill missing values with the median and scale data to unit variance using StandardScaler.\n",
        "\n",
        "- **Categorical Data**: We fill missing values with the most frequent value and convert text categories into binary vectors (One-Hot Encoding).\n",
        "\n",
        "`sklearn`'s pipeline is a tool that allows us to assemble several steps together. It sequentially applies a list of transforms and a final estimator. Intermediate steps of the pipeline must be 'transforms', that is, they must implement fit and transform methods. The final estimator only needs to implement fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Define pipeline for numerical features\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')), # Fill missing values with median\n",
        "    ('scaler', StandardScaler())                   # Standardize features (mean=0, variance=1)\n",
        "])\n",
        "\n",
        "# 2. Define pipeline for categorical features\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')), # Fill missing with mode\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))    # Convert categories to binary vectors\n",
        "])\n",
        "\n",
        "# 3. Combine transformers using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # Apply numerical pipeline to numerical columns\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        # Apply categorical pipeline to categorical columns\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# 4. Create the full end-to-end pipeline including the model\n",
        "# This ensures raw data flows through preprocessing directly into the model\n",
        "model = LogisticRegression()\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('model', model)\n",
        "                          ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training and Evaluation (Logistic Regression)\n",
        "\n",
        "Finally, we split the data into training and testing sets. We fit the entire pipeline on the training data and evaluate its performance on the unseen test data using various classification metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "pos_label=1 is not a valid label. It should be one of ['N', 'Y']",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Calculate classification metrics\u001b[39;00m\n\u001b[32m     11\u001b[39m accuracy = accuracy_score(y_test, preds)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m precision = \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m recall = recall_score(y_test, preds)\n\u001b[32m     14\u001b[39m f1 = f1_score(y_test, preds)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\g_nan\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    207\u001b[39m         skip_parameter_validation=(\n\u001b[32m    208\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    209\u001b[39m         )\n\u001b[32m    210\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    213\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    214\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    215\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    217\u001b[39m     msg = re.sub(\n\u001b[32m    218\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    219\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    220\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    221\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\g_nan\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2127\u001b[39m, in \u001b[36mprecision_score\u001b[39m\u001b[34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1970\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1971\u001b[39m     {\n\u001b[32m   1972\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1996\u001b[39m     zero_division=\u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1997\u001b[39m ):\n\u001b[32m   1998\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[32m   1999\u001b[39m \n\u001b[32m   2000\u001b[39m \u001b[33;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2125\u001b[39m \u001b[33;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[32m   2126\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2127\u001b[39m     p, _, _, _ = \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2128\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2132\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprecision\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2134\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2136\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\g_nan\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    182\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m func_sig = signature(func)\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\g_nan\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1721\u001b[39m, in \u001b[36mprecision_recall_fscore_support\u001b[39m\u001b[34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1563\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[32m   1564\u001b[39m \n\u001b[32m   1565\u001b[39m \u001b[33;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1718\u001b[39m \u001b[33;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[32m   1719\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1720\u001b[39m zero_division_value = _check_zero_division(zero_division)\n\u001b[32m-> \u001b[39m\u001b[32m1721\u001b[39m labels = \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1723\u001b[39m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[32m   1724\u001b[39m samplewise = average == \u001b[33m\"\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\g_nan\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1507\u001b[39m, in \u001b[36m_check_set_wise_labels\u001b[39m\u001b[34m(y_true, y_pred, average, labels, pos_label)\u001b[39m\n\u001b[32m   1505\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m present_labels:\n\u001b[32m   1506\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(present_labels) >= \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1508\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpos_label=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpos_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid label. It \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1509\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshould be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpresent_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1510\u001b[39m             )\n\u001b[32m   1511\u001b[39m     labels = [pos_label]\n\u001b[32m   1512\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[31mValueError\u001b[39m: pos_label=1 is not a valid label. It should be one of ['N', 'Y']"
          ]
        }
      ],
      "source": [
        "# Split data: 80% for training, 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Train the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions\n",
        "preds = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate classification metrics\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "\n",
        "# Calculate ROC curve and AUC score\n",
        "# Note: We use predict_proba for ROC/AUC to get probability scores instead of class labels\n",
        "fpr, tpr, thresholds = roc_curve(y_test, pipeline.predict_proba(X_test)[:,1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Output results\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1 Score: {f1:.2f}')\n",
        "print(f\"AUC: {roc_auc:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Alternative Model (KNN with MinMaxScaler)\n",
        "\n",
        "Now, we recreate the workflow but use min-max scaling for numerical features and KNN classifier for the model. This allows us to compare different preprocessing and modeling approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Redefine numerical pipeline with Min-Max Scaling\n",
        "# Min-Max scaling scales data to a fixed range [0, 1], which preserves the shape of the original distribution\n",
        "numerical_transformer_knn = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')), # Fill missing values\n",
        "    ('scaler', MinMaxScaler())                     # Scale to range [0, 1]\n",
        "])\n",
        "\n",
        "# 2. Update the ColumnTransformer\n",
        "# We reuse the 'categorical_transformer' defined in the previous section (Imputer + OneHotEncoder)\n",
        "preprocessor_knn = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer_knn, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# 3. Define the new model: K-Nearest Neighbors\n",
        "model_knn = KNeighborsClassifier()\n",
        "\n",
        "# 4. Create the new pipeline\n",
        "pipeline_knn = Pipeline(steps=[('preprocessor', preprocessor_knn),\n",
        "                               ('model', model_knn)\n",
        "                              ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Training and Evaluation**\n",
        "\n",
        "We fit this new pipeline to the same training data used previously and evaluate its performance. This allows for a direct comparison between the Logistic Regression (StandardScaler) approach and this KNN (MinMaxScaler) approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the KNN pipeline\n",
        "pipeline_knn.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions\n",
        "preds_knn = pipeline_knn.predict(X_test)\n",
        "\n",
        "# Calculate classification metrics\n",
        "accuracy_knn = accuracy_score(y_test, preds_knn)\n",
        "precision_knn = precision_score(y_test, preds_knn)\n",
        "recall_knn = recall_score(y_test, preds_knn)\n",
        "f1_knn = f1_score(y_test, preds_knn)\n",
        "\n",
        "# Calculate ROC/AUC\n",
        "# Note: KNN supports predict_proba, which allows us to calculate AUC just like Logistic Regression\n",
        "fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, pipeline_knn.predict_proba(X_test)[:,1])\n",
        "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
        "\n",
        "# Output results\n",
        "print(f'Accuracy: {accuracy_knn:.2f}')\n",
        "print(f'Precision: {precision_knn:.2f}')\n",
        "print(f'Recall: {recall_knn:.2f}')\n",
        "print(f'F1 Score: {f1_knn:.2f}')\n",
        "print(f\"AUC: {roc_auc_knn:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Comparison\n",
        "\n",
        "Let's compare the performance of both models side by side:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comparison DataFrame\n",
        "comparison = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC'],\n",
        "    'Logistic Regression': [accuracy, precision, recall, f1, roc_auc],\n",
        "    'KNN (MinMaxScaler)': [accuracy_knn, precision_knn, recall_knn, f1_knn, roc_auc_knn]\n",
        "})\n",
        "\n",
        "print(\"Model Comparison:\")\n",
        "print(comparison.to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
